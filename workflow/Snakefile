configfile: "config.yaml"

rule all:
    input:
        expand("data/sra/sh1000/{srr_sh1000}/{srr_sh1000}.sra", \
                    srr_sh1000 = config["SRR_SH1000"]),
        expand("data/sra/atcc6538/{srr_atcc6538}/{srr_atcc6538}.sra", \
                    srr_atcc6538 = config["SRR_ATCC6538"]),
        expand("data/sra/st398/{srr_st398}/{srr_st398}.sra", \
                    srr_st398 = config["SRR_ST398"]),
        expand("results/atcc6538/{atcc6538_lib}/{atcc6538_lib}.log", \
	        atcc6538_lib = config["ATCC6538_LIB"]),
        expand("results/st398/{st398_lib}/{st398_lib}.log", \
	        st398_lib = config["ST398_LIB"]),
        expand("results/sh1000/{sh1000_lib}/{sh1000_lib}.log", \
	        sh1000_lib = config["SH1000_LIB"]),
        "results/growth_data/20190906_gp_all.png",
        "results/growth_data/20190906_gp_no_sh.png",
        "results/growth_data/20190906_gp_sh.png",
        "results/growth_data/20190906_gp_sh_custom.png"

# need to rejig this into either 3 sra rules (one per strain)
# or to correctly place the downloads into 1 of the 3 dirs
# maybe dictionary in yaml of lib:SRR
# also sra_accession is different to the lib prefix of the fastq filename
# so constructing output names is tricky
# i think the simplest thing to do is to have the pipeline work on SRA
# accessions rather than the original file names

# prefetch .sra to data/sra
# one rule for each genome
# three accession lists in configfile.yaml

# three accession lists (one per genome)
# wildcard prefetch over three accession lists into three directories
# wildcard dump rule 

rule sra:
    input: "data/srr_{strain}.txt"
    output: expand("data/sra/sh1000/{srr_sh1000}/{srr_sh1000}.sra", \
                    srr_sh1000 = config["SRR_SH1000"]),
            expand("data/sra/atcc6538/{srr_atcc6538}/{srr_atcc6538}.sra", \
                    srr_atcc6538 = config["SRR_ATCC6538"]),
            expand("data/sra/st398/{srr_st398}/{srr_st398}.sra", \
                    srr_st398 = config["SRR_ST398"])
    conda: "envs/sra.yaml"
    threads: 6
    shell: "prefetch --output-directory data/sra/{wildcards.strain} --option-file {input}"

#rule dump_sh1000:
#    input: "data/srr_sh1000.txt"
#    output: expand("data/sra/sh1000/{sra_accession}_{mate}.fastq.gz", \
#                    sra_accession = config["SRR"], mate = ["1", "2"])
#    conda: "envs/sra.yaml"
#    threads: 6
#    shell: "prefetch --output-directory data/sra/ --option-file {input}"
#

rule st398_snp:
    input:
        ref="data/st398.gbk",
        mate1="data/st398/{samprefix}_L001_R1_001.fastq.gz",
        mate2="data/st398/{samprefix}_L001_R2_001.fastq.gz"
    output:
        outd=directory("results/st398/{samprefix}"),
        rnl="results/st398/{samprefix}/{samprefix}.log"
    conda: "envs/snippy.yaml"
    threads: 10
    log: "logs/{samprefix}.txt"
    shell: "snippy --cpus {threads} \
		   --outdir {output.outd} \
		   --ref {input.ref} \
                   --prefix {wildcards.samprefix} \
		   --force \
		   --pe1 {input.mate1} --pe2 {input.mate2} 2> {log}"

rule atcc6538_snp:
    input:
        ref="data/atcc6538_combined.gbk",
        mate1="data/atcc6538/{samprefix}_L001_R1_001.fastq.gz",
        mate2="data/atcc6538/{samprefix}_L001_R2_001.fastq.gz"
    output:
        outd=directory("results/atcc6538/{samprefix}"),
        rnl="results/atcc6538/{samprefix}/{samprefix}.log"
    conda: "envs/snippy.yaml"
    threads: 10
    log: "logs/{samprefix}.txt"
    shell: "snippy --cpus {threads} \
		   --outdir {output.outd} \
		   --ref {input.ref} \
                   --prefix {wildcards.samprefix} \
		   --force \
		   --pe1 {input.mate1} --pe2 {input.mate2} 2> {log}"

rule sh1000_snp:
    input:
        ref="data/sh1000_dueppel.gbk",
        mate1="data/sh1000/{samprefix}_L001_R1_001.fastq.gz",
        mate2="data/sh1000/{samprefix}_L001_R2_001.fastq.gz"
    output:
        outd=directory("results/sh1000/{samprefix}"),
        rnl="results/sh1000/{samprefix}/{samprefix}.log"
    conda: "envs/snippy.yaml"
    threads: 10
    log: "logs/{samprefix}.txt"
    shell: "snippy --cpus {threads} \
		   --outdir {output.outd} \
		   --ref {input.ref} \
                   --prefix {wildcards.samprefix} \
		   --force \
		   --pe1 {input.mate1} --pe2 {input.mate2} 2> {log}"

rule growth_data:
    input: csv="data/20190906_growth_data.csv"
    output:
        "results/growth_data/20190906_gp_all.png",
        "results/growth_data/20190906_gp_no_sh.png",
	"results/growth_data/20190906_gp_sh.png",
	"results/growth_data/20190906_gp_sh_custom.png"
    conda: "envs/growth_data.yaml"
    threads: 1
    script: "scripts/growth_data.R"

